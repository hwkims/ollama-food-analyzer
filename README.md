# üç≤ Ollama Food Analyzer üì∏

[![Python Version](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-_-%23FF4B4B)](https://streamlit.io)
[![Made with Ollama](https://img.shields.io/badge/Made%20with-Ollama-_.svg?color=000000&labelColor=FFFFFF)](https://ollama.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A Streamlit web application that analyzes food images using your local Ollama instance with a multimodal vision model (like LLaVA or Granite) to estimate nutritional content, ingredients, and other details.

 ![image](https://github.com/user-attachments/assets/79b226d1-b36a-4eec-b453-870e10a049e2)


## ‚ú® Features

*   Upload food images (JPG, JPEG, PNG).
*   Analyzes images using a local Ollama multimodal model specified in the configuration.
*   Displays analysis results in an organized tabbed interface:
    *   **Summary:** Food name, cuisine type, estimated serving size, confidence level, and notes.
    *   **Nutrients:** Estimated calories, macronutrient breakdown (Carbs, Protein, Fat) with a pie chart, and approximate % of example daily values (with disclaimer).
    *   **Details:** Estimated detailed ingredients, guessed preparation method, and potential allergens (with disclaimer).
    *   **Raw JSON:** The complete JSON output received from the Ollama model.
*   User-friendly interface built with Streamlit.
*   Handles connection errors and model response parsing issues gracefully.

## üõ†Ô∏è Tech Stack

*   **Python 3.8+**
*   **[Streamlit](https://streamlit.io/):** For creating the web interface.
*   **[Ollama](https://ollama.com/):** For running the local large language model. Requires a vision-capable model installed (e.g., `granite3.2-vision`, `llava`).
*   **[Requests](https://requests.readthedocs.io/):** For making API calls to the Ollama server.
*   **[Plotly](https://plotly.com/python/):** For generating the macronutrient pie chart.

## üöÄ Setup & Installation

1.  **Prerequisites:**
    *   **Python:** Ensure you have Python 3.8 or newer installed.
    *   **Ollama:** Install and run Ollama locally. Follow the instructions on the [Ollama website](https://ollama.com/).
    *   **Ollama Vision Model:** Pull a vision-capable model. Open your terminal and run (choose one or another suitable model):
        ```bash
        ollama pull granite3.2-vision
        # or
        ollama pull llava
        ```
        Make sure the Ollama application/server is running in the background.

2.  **Clone the Repository:**
    ```bash
    git clone https://github.com/hwkims/ollama-food-analyzer.git
    cd ollama-food-analyzer
    ```

3.  **Install Dependencies:**
    *   (Recommended) Create and activate a virtual environment:
        ```bash
        # Windows
        python -m venv .venv
        .\.venv\Scripts\activate

        # macOS/Linux
        python -m venv .venv
        source .venv/bin/activate
        ```
    *   Install the required Python packages:
        ```bash
        pip install streamlit requests plotly
        ```

4.  **Configuration (Optional):**
    *   Open the Python script (`enhanced_food_analyzer.py` or your filename).
    *   Check the `Configuration` section near the top:
        *   `OLLAMA_API_URL`: Ensure this matches your local Ollama API endpoint (default `http://127.0.0.1:11434/api/generate` is usually correct).
        *   `OLLAMA_MODEL`: Change this to the exact name of the vision model you pulled and want to use (e.g., `"llava"` or `"granite3.2-vision"`).
        *   `REQUEST_TIMEOUT`: Adjust if your model takes longer to respond.

5.  **Run the Application:**
    ```bash
    streamlit run enhanced_food_analyzer.py
    ```
    (Replace `enhanced_food_analyzer.py` with the actual name of your Python file if you saved it differently).

    This will open the application in your web browser.

## üìñ Usage

1.  Launch the application using the `streamlit run` command.
2.  Click the "Browse files" button or drag and drop a food image onto the uploader.
3.  Wait for the Ollama model to analyze the image (a spinner will indicate progress).
4.  View the analysis results displayed in the tabs on the right side.
5.  Upload another image to analyze a different food item.

## ‚ö†Ô∏è Disclaimer

The nutritional information, ingredients, allergens, and other details provided by this application are **estimates generated by an AI model** based on visual interpretation and general knowledge.

*   **Accuracy is not guaranteed.** Actual values can vary significantly depending on specific ingredients, preparation methods, portion sizes, and other factors.
*   **This is not dietary advice.** Consult a qualified nutritionist or healthcare professional for accurate dietary information and guidance.
*   **Allergen information is indicative only.** It's based on typical recipes and visual cues, and does not account for cross-contamination. Always verify ingredients if you have food allergies.

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file (or add the MIT license text here) for details.
